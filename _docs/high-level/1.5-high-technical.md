

# Scientific Measurement Copilot – Concept & Rationale

## 1. Vision (WHAT are we building?)

A **browser‑based copilot** that helps researchers:

1. Load scientific data (images, volumes, CSVs, etc.).
2. Interactively **segment** or **select** regions of interest (ROIs) using SAM‑style models or manual tools.
3. Run **arbitrary quantitative measurements** (distances, areas, angles, intensity, derived indices) using **Python/NumPy/SciPy** executed via **Pyodide in the browser**.
4. Get results explained, plotted, and exported—all orchestrated through **natural‑language chat** using the **Vercel AI SDK**.

Think of it as:

> “Jupyter + ImageJ + a good postdoc, embedded in your browser and controlled by chat.”

The osteoarthritis example (Tang ratios) is **one preset workflow** that the copilot can do. The core app should support *any* measurement you can express as:
- “Take this region / mask / set of points”
- “Apply this computation”
- “Report this number / plot / table”

---

## 2. Motivation (WHY does this need to exist?)

### Pain points in current scientific workflows

1. **Fragmented tools**
   - Imaging in Fiji/ImageJ
   - Analysis in Python / MATLAB
   - Notes and rationale in Word / PowerPoint
   - Nothing “remembers” the entire chain from raw data to figure.

2. **High friction for non‑programmers**
   - Many biologists / clinicians know what they want measured, but not how to translate that into code.
   - Even “simple” tasks (e.g., “measure the area of all nuclei and plot a histogram”) require dozens of lines of code or complex ImageJ macros.

3. **Reproducibility and traceability**
   - Ad‑hoc manual measurements are hard to audit.
   - “Click here and read that number” is not a reproducible pipeline.

4. **Backend complexity**
   - Traditional solutions require a dedicated Python backend, GPUs, etc.
   - You explicitly want to avoid that and keep things light.

### Why a Chat‑driven, Client‑heavy Tool?

- **Natural language as the interface**:
  - “Segment mitochondria and compute their aspect ratio distribution.”
  - “Compare average fluorescence intensity in treated vs control regions.”
- **Pyodide in the browser** lets us:
  - Reuse the entire scientific Python ecosystem (NumPy, SciPy, scikit‑image, pandas) *without* hosting a Python service.
  - Keep data local (good for privacy / compliance and large files).
- **Vercel AI SDK**:
  - Handles the chat loop and tool calling with minimal backend code.
  - Lets the LLM orchestrate tools instead of you writing glue logic.

---

## 3. Target Research Workflows (WHAT should it support?)

The app should support a **family** of workflows, of which Tang OA is one concrete example.

### 3.1. Generic Image‑Based Measurement Workflow

**User goal:** “I have an image; I want to measure X.”

1. **Load & Calibrate**
   - User drags in an image (microscopy, radiology, gel, etc.).
   - If needed, user draws a line over a scale bar and enters real‑world length → app computes `units_per_pixel`.

2. **Define Regions of Interest (ROIs)**
   - Via chat: “Segment the cell nuclei” / “Segment the bone.”
   - LLM calls a tool that uses SAM‑like API (Fal.ai, etc.).
   - Alternatively: user draws polygons/boxes/points manually.

3. **Specify Measurement via Language**
   - Examples:
     - “Measure the area of each nucleus and give mean ± SD.”
     - “Compute the shortest distance between this vessel and this tumor boundary.”
     - “For each bone region, compute trabecular thickness and spacing proxies.”
     - “Calculate the ratio of cartilage thickness to bone width across slices.”

4. **Computation in Pyodide**
   - LLM turns the request into a call to a generic Python tool:
     - Passes masks / coordinates / image data to Pyodide.
     - Runs NumPy / SciPy / scikit‑image code to compute metrics.
   - Returns structured results (numbers, arrays, stats).

5. **Visualization & Export**
   - Show overlays (e.g., colored masks, measurement lines).
   - Plot histograms, scatter plots, or time series (via matplotlib in Pyodide or JS charts).
   - Append results to an in‑app “Results Table” → export as CSV/JSON.

### 3.2. Examples of Arbitrary Measurements

The same framework can cover:

- **Cell biology**
  - Nuclear area, circularity, intensity.
  - Colocalization (Pearson correlation between channels).
- **Neuroscience**
  - Neurite length, branching patterns.
  - Distance from soma to synapse clusters.
- **Pathology**
  - Tumor‑stroma ratio.
  - Vessel density per unit area.
- **Materials science**
  - Grain size distributions.
  - Crack length and orientation.
- **Classic OA (Tang)**
  - Distal femur width/length ratio.
  - Tibial height/width ratio.

All of these are just: **image/ROI + geometry/intensity operations**.

---

## 4. Conceptual Architecture (HOW, at a high level)

### 4.1. Frontend‑centric design

Everything runs in the browser except:
- LLM calls (Vercel AI SDK → model provider)
- Optional cloud segmentation (SAM API)

Key components:

1. **Chat Panel (Vercel AI SDK)**
   - Users describe tasks and review explanations.
   - LLM calls “tools” that are actually **client‑side functions** (via custom handlers).

2. **Canvas Panel (React‑Konva or similar)**
   - Displays images and ROIs.
   - Manages layers: raw image, masks, measurement overlays.

3. **Pyodide Worker**
   - Loaded once per session.
   - Exposes a generic `runPython(code: string, inputs: any): Promise<any>` interface.
   - Encapsulates reusable Python “modules” for geometry & stats.

4. **Segmentation Client (optional)**
   - Calls a remote SAM‑3/SAM‑2 style API.
   - Returns masks / polygons as arrays.

### 4.2. Tool Types (Generic, not OA‑specific)

The LLM should see a **small, composable set of tools**, not OA‑hard‑coded ones:

1. **`segmentImage`**
   - Inputs: `prompt: string`, optional `points` or `box`.
   - Output: `maskId`, mask polygon or bitmap.

2. **`createROI` / `editROI`**
   - For manual drawing or user correction.
   - Lets user refine what the model selected.

3. **`runPythonMeasurement`**
   - Inputs: 
     - `operationName: string` (e.g., "bounding_box", "distance", "area", "custom_code")
     - `maskIds` / `points` / `imageChannel` references
     - `parameters: object` (e.g., thresholds, units_per_pixel)
   - Internally:
     - Maps `operationName` to a Python snippet or function.
     - Uses NumPy, SciPy, scikit‑image, pandas.

4. **`saveResult`**
   - Appends a record to an in‑app dataset: `{ sampleId, operation, values, metadata }`.

The OA ratios become a **preset macro**:
- “Tang_OA_FemurRatio(maskIdFemur)” → internally calls:
  - `runPythonMeasurement("bounding_box")`  
  - `runPythonMeasurement("ratio")`
  - Applies OA‑specific interpretation thresholds.

---

## 5. Roles of Pyodide and Vercel AI SDK (WHY each is essential)

### Pyodide (Client‑side Python)

**Why Pyodide?**
- You get to reuse the **scientific Python ecosystem**:
  - NumPy for arrays and linear algebra
  - SciPy/scikit‑image for morphology & filtering
  - pandas for tabular summarization
- No backend maintenance:
  - No Flask/FastAPI/Gunicorn to deploy.
  - Works offline once loaded; all data can stay local.

**What Pyodide does:**
- Acts as the “analysis engine.”
- Runs parameterized Python “recipes” generated or selected by the LLM.
- Provides strict, deterministic computations (no hallucinated formulas).

### Vercel AI SDK (Chat + Tool Orchestration)

**Why Vercel AI SDK?**
- Integrates chat, streaming, and tool calls with minimal boilerplate.
- Lets you define TypeScript tool schemas once and have the LLM call them correctly.
- Fits perfectly into a “no/low backend” Next.js + edge deployment.

**What the SDK does:**
- Parses user requests (“measure cell area”) and determines:
  - When to call segmentation.
  - When to call `runPythonMeasurement`.
  - When to ask the user to confirm ROIs.
- Communicates results back as:
  - Explanations in plain language.
  - Structured data to be rendered as tables/plots.

---

## 6. Design Principles

1. **Generic first, domain second**
   - Core operations: segment, select, measure, summarize.
   - Domain‑specific presets (Tang OA, neurite tracing, etc.) are templates on top.

2. **Human‑in‑the‑loop**
   - Always give the user a chance to inspect and correct ROIs and calipers before final computation.

3. **Traceable pipelines**
   - Every result should be reproducible:
     - Input image/version
     - ROIs/masks used
     - Exact Python code run
     - Parameters and thresholds
   - Allow exporting a “recipe” as a small JSON+Python snippet.

4. **Minimal backend**
   - Only the LLM and optional segmentation live on the server.
   - All heavy compute (math, geometry, stats) runs in the browser via Pyodide.

